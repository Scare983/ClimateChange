{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling Temperature based off greenhouse gases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scraping code to get all the data, but not included in here as there was parsing afterwards to make sure the data was correct.  May include at end of notebook to show how the data was taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WorldController class is used to parse weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from StateObj import StateObj, findState\n",
    "from matplotlib import pyplot\n",
    "from DataModifier import DateMod\n",
    "#change this class to contioulsy run in future.\n",
    "\n",
    "##MAIN##\n",
    "\n",
    "## CREATE/PARSE DATA FOR ML MODEL##\n",
    "\n",
    "\n",
    "##CREATE OBJECTS FOR EACH CITY##\n",
    "## City obj will handle data passed in through none statements\n",
    "#CountryObj() # only do UNITED STATES\n",
    "class WorldController:\n",
    "    def __init__(self, oo = False):\n",
    "        if oo:\n",
    "            cityCountryDict = {}\n",
    "            for file in glob.glob(\"./data/weather/*City*\"):\n",
    "                weatherCityData = pd.read_csv(file, header=0, index_col='dt', infer_datetime_format=True)\n",
    "                weatherCityData = weatherCityData[weatherCityData['Country'] == 'United States' ]\n",
    "\n",
    "                weatherGroup = weatherCityData.groupby(['Longitude', 'Latitude'])\n",
    "\n",
    "                for  key, item in weatherGroup:\n",
    "                    for city in item.City.unique():\n",
    "                        cityCountryDict[city]   =  {'Location': [*item.Longitude.unique(), *item.Latitude.unique()]}\n",
    "                # remove break\n",
    "\n",
    "            allWeatherCityData = pd.DataFrame()\n",
    "            for file in glob.glob(\"./data/weather/*City*\"):\n",
    "                weatherCityData = pd.read_csv(file, header=0, index_col='dt')\n",
    "\n",
    "                weatherCityData = weatherCityData[weatherCityData['Country'] == 'United States']\n",
    "                weatherCityData.index = pd.to_datetime(weatherCityData.index)\n",
    "                weatherCityData = weatherCityData[weatherCityData.index.year >= 1960]\n",
    "                weatherCityData = weatherCityData[weatherCityData.index.year < 2012]\n",
    "                allWeatherCityData = allWeatherCityData.append(weatherCityData)\n",
    "                for key in cityCountryDict.keys():\n",
    "                    #pd.DataFrame(weatherCityData['AverageTemperature'].resample('W').sum(), columns=['AverageTemperature'])\n",
    "                    weatherDict = weatherCityData[weatherCityData['City'] == key]['AverageTemperature']\n",
    "                    i = 0\n",
    "                    cityCountryDict[key]['time'] = []\n",
    "                    for date in weatherDict.index.to_pydatetime():\n",
    "                        otherDict = {date.strftime(\"%Y-%m-%d\"): weatherDict.values[i]}\n",
    "                        cityCountryDict[key]['time'].append(otherDict)\n",
    "                        i+=1\n",
    "                # remove break\n",
    "\n",
    "            #cityCountryDict has City as key, Location : [longitude, latitude], time: [{WEEK TIMESTAMP : weather}...*]. Each child will find data to fit with its parent classes to pass data to it.  (read the csv, etc.)\n",
    "            allStateData = pd.read_csv('./data/weather/GlobalLandTemperaturesByState.csv')\n",
    "            allStateData = allStateData[allStateData['Country'] =='United States']\n",
    "            allStateData.dt = pd.to_datetime(allStateData.dt)\n",
    "            allStateData = allStateData.set_index(drop=True, keys='dt')\n",
    "\n",
    "            #get weather data from 1960 and above.\n",
    "            allStateData = allStateData[allStateData.index.year>=1960]#.resample('W').mean()['AverageTemperature']\n",
    "            allStateData = allStateData[allStateData.index.year<2012]\n",
    "            allStates = []\n",
    "            for state in allStateData['State'].unique():\n",
    "                otherData = allStateData[allStateData['State'] == state]\n",
    "                allStates.append(StateObj(state, otherData))\n",
    "\n",
    "\n",
    "            for city in cityCountryDict.keys():\n",
    "                 cityStateName = findState(longitude=cityCountryDict[city]['Location'][0], latitude=cityCountryDict[city]['Location'][1])\n",
    "                 for state in allStates:\n",
    "                     if cityStateName == state.getStateName():\n",
    "                         state.createCity(longitude=cityCountryDict[city]['Location'][0], latitude=cityCountryDict[city]['Location'][1], cityName=city, data=cityCountryDict[city]['time'])\n",
    "                         #need this break.  Found the state.\n",
    "                         break\n",
    "                     if cityStateName == 'StateNA':\n",
    "                         state.createCity(longitude=cityCountryDict[city]['Location'][0], latitude=cityCountryDict[city]['Location'][1], cityName=city, data=cityCountryDict[city]['time'])\n",
    "                         break\n",
    "\n",
    "\n",
    "            # this is only class attribute that will be used\n",
    "            self.states = allStates\n",
    "            self.longLat = weatherCityData\n",
    "\n",
    "\n",
    "        else:\n",
    "            weatherCityData = pd.read_csv('./data/weather/unitedStatesTemp.csv', header=0, index_col='dt')\n",
    "            weatherCityData.index = pd.to_datetime(weatherCityData.index)\n",
    "            weatherCityData = weatherCityData[weatherCityData.index.year >= 1960]\n",
    "            weatherCityData = weatherCityData[weatherCityData.index.year <= 2012]\n",
    "            weatherCityData.Latitude = weatherCityData.Latitude.apply(parseLat)\n",
    "            weatherCityData.Longitude = weatherCityData.Longitude.apply(parseLong)\n",
    "\n",
    "            self.monthDict = {1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None, 11: None, 12:None}\n",
    "            for name, group in weatherCityData.groupby(by=[weatherCityData.index.month]):\n",
    "\n",
    "                self.monthDict[group.index[0].month] = group\n",
    "            #print (monthDict)\n",
    "            averageMonthDict = {1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None, 11: None, 12:None}\n",
    "            for dataFrame in self.monthDict.keys():\n",
    "                averageMonthDict[dataFrame] = self.monthDict[dataFrame].groupby(by=self.monthDict[dataFrame].index).agg('mean')['AverageTemperature']\n",
    "            #monthDict[1].to_csv('month1 temperatures')\n",
    "            self.graphMonthlyChange(averageMonthDict)\n",
    "            self.calculatePerIncrease(averageMonthDict)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculatePerIncrease(self, aDict):\n",
    "        for key in aDict.keys():\n",
    "            print('%increase for month {}  == {}'.format(key, ((aDict[key][-1] - aDict[key][0])/aDict[key][0])*100 ) )\n",
    "\n",
    "\n",
    "    def graphMonthlyChange(self, aDict):\n",
    "        for key in aDict.keys():\n",
    "            pyplot.plot(aDict[key], label=key)\n",
    "        #pyplot.plot(graphed)\n",
    "        pyplot.xlabel('Years')\n",
    "        pyplot.ylabel('Temperature in Celsius')\n",
    "        pyplot.legend()\n",
    "        pyplot.savefig('./generatedData/monthDataWithlegend')\n",
    "\n",
    "        pyplot.figure().clear()\n",
    "\n",
    "    def getDfToTrain(self,sf6, n2o, co2, ch4):\n",
    "        sf6 = self.createMonthYear(sf6)\n",
    "        n2o = self.createMonthYear(n2o)\n",
    "        co2 = self.createMonthYear(co2)\n",
    "        ch4 = self.createMonthYear(ch4)\n",
    "        dfMonthArray = []\n",
    "        for keys in self.monthDict:\n",
    "            month1 = pd.DataFrame(self.monthDict[keys][['AverageTemperature', 'Latitude', 'Longitude']])\n",
    "            month1['sf6'] = np.nan\n",
    "            month1['n2o'] = np.nan\n",
    "            month1['co2'] = np.nan\n",
    "            month1['ch4'] = np.nan\n",
    "            monthParsed = month1.reset_index()\n",
    "            i =0\n",
    "            for index, row in monthParsed.iterrows():\n",
    "                #print(sf6.loc[index.date()].values[0])\n",
    "                ymRow = \"{}/{}\".format(row['dt'].year, row['dt'].month)\n",
    "                month1['sf6'].iloc[i] = sf6[sf6['index'] == ymRow]['average'].values[0]\n",
    "                month1['n2o'].iloc[i] = n2o[n2o['index'] == ymRow]['average'].values[0]\n",
    "                month1['co2'].iloc[i] = co2[co2['index'] == ymRow]['CarbonEmissions'].values[0]\n",
    "                month1['ch4'].iloc[i] = ch4[ch4['index'] == ymRow]['sum'].values[0]\n",
    "                i+=1\n",
    "            month1.reset_index(drop=True, inplace=True)\n",
    "            dfMonthArray.append(month1)\n",
    "        return dfMonthArray\n",
    "\n",
    "    def getMonthDict(self):\n",
    "        return self.monthDict\n",
    "    \n",
    "    def createMonthYear(self, df):\n",
    "        sf6YearMonth = []\n",
    "        for i in range(0, len(df.index.year)):\n",
    "            sf6YearMonth.append('{}/{}'.format(df.index[i].year, df.index[i].month ))\n",
    "        df = df.reset_index()\n",
    "        df['index'] = pd.Series(sf6YearMonth)\n",
    "        return df\n",
    "\n",
    "    def train_state_models(self):\n",
    "        stateModel = \"\" # should be linear/log model\n",
    "        for state in self.states:\n",
    "            #get each state name, use it in conjuncation with the greenhouse gasses.\n",
    "            state.getStateName()\n",
    "        return stateModel\n",
    "\n",
    "    def train_city_models(self):\n",
    "        pass\n",
    "def parseLong( longitude): #east negative\n",
    "    if 'E' in longitude:\n",
    "        return   float(longitude.replace('E', ''))\n",
    "    else:\n",
    "        return (-1) * float(longitude.replace('W', ''))\n",
    "\n",
    "def parseLat( latitude): #north south\n",
    "    if 'S' in latitude:\n",
    "        return  (-1) *float(latitude.replace('S', ''))\n",
    "    else:\n",
    "        return float(latitude.replace('N', ''))\n",
    "## Right here, create ML model.\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "\n",
    "#Once city populated, inf. while loop to get input for a city/state/country day(the next days sf6/co2/ch4/etc\n",
    "# levels will be calculted and put into the model we have trained to predict #\n",
    "#given a day, calculate greenhouse level gasses from our formula, and input to city params to be processed with given data\n",
    "#if __name__ == \"__main__\":\n",
    "#    WorldController()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have created an object that stores three dataframes when used. One for months, days, and weeks in case we want to use different types of time periods for predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from calendar import monthrange\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "class DateMod():\n",
    "    yearDataFrame = None\n",
    "    monthDataFrame = None\n",
    "    weekDataFrame = None\n",
    "    dayDataFrame = None\n",
    "    dataName = None\n",
    "    colVa1 = None\n",
    "    def __init__(self, df, colValName, name):\n",
    "        if \"month\" in df.keys():\n",
    "            self.month_to_days(df,colValName)\n",
    "        elif 'year' in df.keys():\n",
    "            self.year_to_days(df,colValName)\n",
    "        self.dataName = name\n",
    "        self.colVal = colValName\n",
    "        #TODO: fill in nan values created from months_to_day (They will = 0) to predicted ones.\n",
    "    # testing on ch4, go up to 2014\n",
    "    #returns dataframe with datetime as index, and values for each day given\n",
    "    def year_to_days(self,df, colValName):\n",
    "        dateObjs = []\n",
    "        dateVals = []\n",
    "        for i, y in enumerate(df.year):\n",
    "            if y >= 1960:\n",
    "                start = dt.date(y, 1, 1)\n",
    "                end = dt.date(y+1,1, 1)\n",
    "                date = start\n",
    "                days = (end - start).days\n",
    "                value = df[colValName][i]\n",
    "                while date != end:\n",
    "                    dateObjs.append(date)\n",
    "                    dateVals.append(value/days)\n",
    "                    date += dt.timedelta(days=1)\n",
    "        df = pd.DataFrame(dateVals, index=dateObjs, columns=[colValName])\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        self.dayDataFrame = df\n",
    "        self.yearDataFrame = pd.DataFrame(df[colValName].resample('Y').sum(), columns=[colValName])\n",
    "        self.monthDataFrame = pd.DataFrame(df[colValName].resample('M').sum(), columns=[colValName])\n",
    "        self.weekDataFrame = pd.DataFrame(df[colValName].resample('W').sum(), columns=[colValName])\n",
    "    def month_to_days(self, df, colValName):\n",
    "        dateObjs = []\n",
    "        dateVals = []\n",
    "        if int(df.year[0]) > 1960:\n",
    "\n",
    "            diff = int(df.year[0]) - 1960\n",
    "            # find delta, and append to month range list\n",
    "\n",
    "            for year in range(diff+1):\n",
    "                for month in range(1, 13):\n",
    "                    # check if current year needs months added\n",
    "                    if 1960+year == int(df.year[0]) and int(df.month[0]) == month:\n",
    "                        break\n",
    "                    for days in range(1, (monthrange(int(df.year[0]) + year, month)[1])):\n",
    "                        dateObjs.append(dt.datetime(1960+year, month, days))\n",
    "                        dateVals.append(np.nan)\n",
    "        # add known dates to monthrange\n",
    "        for index, row in df.iterrows():\n",
    "            # check if row and month exist in delta time, if it doesn't add it.\n",
    "\n",
    "            numDaysInMonth = (monthrange(int(row['year']), int(row['month']))[1])\n",
    "            valueToAppendToDay = int(row[colValName])/numDaysInMonth\n",
    "            for days in range(1, numDaysInMonth+1):\n",
    "                dateObjs.append(dt.datetime(int(row['year']), int(row['month']), days))\n",
    "                dateVals.append(valueToAppendToDay)\n",
    "\n",
    "        # TODO HERE:  add dates after the end date of the given df to equal 2019.... maybe..\n",
    "        df = pd.DataFrame(dateVals, index=dateObjs, columns=[colValName])\n",
    "        Y = regrade_lin([x for x in range(len(df[colValName].values.tolist()))],df[colValName].values.tolist())\n",
    "        for val in Y:\n",
    "            if val > 0:\n",
    "                try:\n",
    "                    foo = 1/val\n",
    "                except ZeroDivisionError:\n",
    "                    continue\n",
    "                set = val\n",
    "                break\n",
    "        for i, v in enumerate(Y):\n",
    "            if v < 0.0000001 or v == 0:\n",
    "                Y[i] = set\n",
    "        df[colValName] = Y\n",
    "        self.dayDataFrame = df\n",
    "        self.yearDataFrame = pd.DataFrame(df[colValName].resample('Y').sum(), columns=[colValName])\n",
    "        self.monthDataFrame = pd.DataFrame(df[colValName].resample('M').sum(), columns=[colValName])\n",
    "        self.weekDataFrame = pd.DataFrame(df[colValName].resample('W').sum(), columns=[colValName])\n",
    "\n",
    "    def graphMonths(self, name):\n",
    "        plt.plot(self.monthDataFrame)\n",
    "        plt.savefig('/generatedData/{}_month_graph'.format(name))\n",
    "        plt.figure().clear()\n",
    "    def graphWeeks(self,name):\n",
    "        plt.plot(self.weekDataFrame)\n",
    "        plt.savefig('/generatedData/{}_weeks_graph'.format(name))\n",
    "        plt.figure().clear()\n",
    "    def graphDays(self,name):\n",
    "        plt.plot(self.dayDataFrame)\n",
    "        plt.savefig('/generatedData/{}_days_graph'.format(name))\n",
    "        plt.figure().clear()\n",
    "\n",
    "def regrade_lin(x, y):#returns the missing values of y\n",
    "    missing = []\n",
    "    n = 0\n",
    "    sumx = 0\n",
    "    sumy = 0\n",
    "    sum_prodxy = 0\n",
    "    sum_squarex = 0\n",
    "    sum_squarey = 0\n",
    "    for i,v in enumerate(y):\n",
    "        if pd.isna(v) or pd.isna(x[i]):\n",
    "            missing.append(i)\n",
    "        if not pd.isna(v) and not pd.isna(x[i]):\n",
    "            n+=1\n",
    "            sumx += x[i]\n",
    "            sumy += v\n",
    "            sum_prodxy += x[i]*v\n",
    "            sum_squarex += x[i]**2\n",
    "            sum_squarey += v**2\n",
    "    #some method from the internet\n",
    "    #a = (sumy*sum_squarex - sumx*sum_prodxy)/(n*sum_squarex - sumx**2)\n",
    "    #b = (n*sum_prodxy - sumx*sumy)/(n*sum_squarex - sumx**2)\n",
    "    #method of least squares\n",
    "    b = (sum_prodxy-(sumx*sumy)/n)/(sum_squarex-(sumx**2)/n)#b1\n",
    "    a = (1/n)*(sumy - b*sumx)#b0\n",
    "    #y = a + bx\n",
    "    #x = (y - a)/b\n",
    "    for i in missing:\n",
    "        if pd.isna(x[i]):\n",
    "            x[i] = (y[i] - a)/b\n",
    "        else:\n",
    "            y[i] = a + b*x[i]\n",
    "    return y\n",
    "\n",
    "def IPA(df):#value Increase in Percentage Averaged over intervals\n",
    "    ratios = []\n",
    "    interval = [] \n",
    "    for i,new in enumerate(df):\n",
    "        if i != 0:\n",
    "            ratios.append(((new-old)/old)*100)\n",
    "        old = new\n",
    "    #(len(ratios))\n",
    "    avg = sum(ratios)/len(ratios)\n",
    "    return [ratios,interval]\n",
    "# if called from main, we want to test this file, so create dataframes and pass em in.\n",
    "# TODO: might want to put graph_all, and graph_weekly into new class, along with our training models.\n",
    "def test_code(debug):\n",
    "    sf6_data = pd.read_csv('./data/Sf6/sf6_mm_gl.csv', header=0)\n",
    "    sf6_obj = DateMod(sf6_data, 'average','sf6')\n",
    "    n2o_data = pd.read_csv('./data/N2o/n2o_mm_gl.csv',header=0)\n",
    "    n2o_obj = DateMod(n2o_data, 'average', 'n2o')\n",
    "    \n",
    "    ch4_txt = open('./data/Ch4/ch4_mm_gl.txt',mode='r')\n",
    "    ch4_data = dict()\n",
    "    keys = ch4_txt.readline().split()\n",
    "    for key in keys:\n",
    "        ch4_data[key] = []\n",
    "    for line in ch4_txt:\n",
    "        for i, v in enumerate(line.split()):\n",
    "            ch4_data[keys[i]].append(v)\n",
    "    ch4_data = pd.DataFrame(ch4_data)\n",
    "    ch4_data = ch4_data.apply(pd.to_numeric)\n",
    "    ch4_obj = DateMod(ch4_data, 'average', 'ch4')\n",
    "    co2_data = pd.read_csv('./data/CO2Emission/global.1751_2014.csv', header=0)\n",
    "    co2_data = co2_data.rename(columns={'Year':'year','Total carbon emissions from fossil fuel consumption and cement production (million metric tons of C)':'CarbonEmissions'})\n",
    "    co2_data = co2_data.loc[:,['year','CarbonEmissions']]\n",
    "    co2_data = co2_data.drop(co2_data.index[0]).reset_index(drop=True)\n",
    "    co2_data = co2_data.apply(pd.to_numeric)\n",
    "    co2_obj = DateMod(co2_data,'CarbonEmissions','co2')\n",
    "\n",
    "def usage():\n",
    "    print('python DataModifier [-d]')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##MAIN METHOD##\n",
    "#if __name__ == '__main__':\n",
    "#    import getopt\n",
    "#    import sys\n",
    "#    debug = False\n",
    "#    try:\n",
    "#        opt, args = getopt.getopt(sys.argv[1:], \"d\")\n",
    "#    except getopt.GetoptError:\n",
    "#        usage()\n",
    "#        sys.exit(2)\n",
    "#    for opts, arg in opt:\n",
    "#        if opts == '-d':\n",
    "#            debug = True\n",
    "#\n",
    "#\n",
    "#    test_code(debug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our MAIN Class that gathers all greenhouse gas data and parses through it.  \n",
    "It creates a WorldController Obj that we will use to get our trained models once we call the train methods.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CH4_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-869ad4fbf3ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mch4_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDateMod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch4_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'average'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ch4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mch4_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertDFIntoMonthDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCH4_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonthDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCH4_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonthDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m2012\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# Don't know how to do these conversion.  Need help.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CH4_obj' is not defined"
     ]
    }
   ],
   "source": [
    "from WorldController import WorldController\n",
    "from DataModifier import DateMod, IPA\n",
    "import pandas as pd\n",
    "import glob\n",
    "# worldController takes care of temperature/longitude\n",
    "#datamodifer is used to modify other data\n",
    "\n",
    "def convertDFIntoMonthDict(dataFrame):\n",
    "    monthDict = {1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None, 11: None, 12:None}\n",
    "    for name, group in dataFrame.groupby(by=[dataFrame.index.month]):\n",
    "        monthDict[group.index[0].month] = group\n",
    "    return monthDict\n",
    "\n",
    "sf6_data = pd.read_csv('./data/Sf6/sf6_mm_gl.csv', header=0)\n",
    "sf6_obj = DateMod(sf6_data, 'average','sf6')\n",
    "sf6_dict = convertDFIntoMonthDict(sf6_obj.monthDataFrame[sf6_obj.monthDataFrame.index.year <2012])\n",
    "\n",
    "sf6_obj.monthDataFrame.to_csv('sf6_month_data')\n",
    "\n",
    "n2o_data = pd.read_csv('./data/N2o/n2o_mm_gl.csv',header=0)\n",
    "n2o_obj = DateMod(n2o_data, 'average','n2o')\n",
    "n2o_obj.monthDataFrame.to_csv('N20_month_data')\n",
    "n2o_dict = convertDFIntoMonthDict(n2o_obj.monthDataFrame[n2o_obj.monthDataFrame.index.year <2012])\n",
    "\n",
    "ch4_data = dict()\n",
    "ch4_txt = open('./data/Ch4/ch4_mm_gl.txt',mode='r')\n",
    "keys = ch4_txt.readline().split()\n",
    "for key in keys:\n",
    "    ch4_data[key] = []\n",
    "for line in ch4_txt:\n",
    "    for i, v in enumerate(line.split()):\n",
    "        ch4_data[keys[i]].append(v)\n",
    "ch4_data = pd.DataFrame(ch4_data)\n",
    "ch4_data = ch4_data.apply(pd.to_numeric)\n",
    "ch4_obj = DateMod(ch4_data, 'average', 'ch4')\n",
    "\n",
    "ch4_dict = convertDFIntoMonthDict(CH4_obj.monthDataFrame[CH4_obj.monthDataFrame.index.year <2012])\n",
    "\n",
    "# Don't know how to do these conversion.  Need help.\n",
    "#ignoring the per capita data, we will use the yearly carbon emmision data and divide it into days then weeks and months\n",
    "co2_data = pd.read_csv('./data/CO2Emission/global.1751_2014.csv', header=0)\n",
    "co2_data = co2_data.rename(columns={'Year':'year','Total carbon emissions from fossil fuel consumption and cement production (million metric tons of C)':'CarbonEmissions'})\n",
    "co2_data = co2_data.loc[:,['year','CarbonEmissions']]\n",
    "co2_data = co2_data.drop(co2_data.index[0]).reset_index(drop=True)\n",
    "co2_data = co2_data.apply(pd.to_numeric)\n",
    "co2_obj = DateMod(co2_data,'CarbonEmissions','co2')\n",
    "#print(joinedCH4)\n",
    "co2_dict = convertDFIntoMonthDict(co2_obj.monthDataFrame[co2_obj.monthDataFrame.index.year <2012])\n",
    "\n",
    "\n",
    "greenhouse = [sf6_obj,n2o_obj,ch4_obj, co2_obj]\n",
    "for obj in greenhouse:\n",
    "    #print(IPA(obj.monthDataFrame[obj.monthDataFrame.keys().tolist()[0]]))\n",
    "    pass\n",
    "# initialize weather data into objs.\n",
    "\n",
    "\n",
    "\n",
    "    #nitDf = pd.DataFrame()\n",
    "    #allWeatherLongLat =  pd.concat(allWeatherLongLat, initDf)\n",
    "    #print(allWeatherLongLat)\n",
    "#self,sf6, n2o, co2, ch4\n",
    "\n",
    "#mainControl.train_long_lat_model(None,None,None,None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train our model from our mainController "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainControl = WorldController()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayOfDataToTrain = mainControl.getDfToTrain(sf6_obj.monthDataFrame[sf6_obj.monthDataFrame.index.year <=2012], n2o_obj.monthDataFrame[n2o_obj.monthDataFrame.index.year <=2012], co2_obj.monthDataFrame[co2_obj.monthDataFrame.index.year <=2012], CH4_obj.monthDataFrame[CH4_obj.monthDataFrame.index.year <=2012])\n",
    "    \n",
    "#now we have an array with dataframes for each month, return several models.  One for each month.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "linearModel = []\n",
    "i = 1\n",
    "for df in arrayOfDataToTrain:\n",
    "    x =  df[df.columns[1:]]\n",
    "    y = df[df.columns[0]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=42)\n",
    "    linMod = LinearRegression().fit(X_train, y_train)\n",
    "    linearModel.append(linMod)\n",
    "    plt.title(f'month: {i}')\n",
    "    plt.plot(y_test, label='real')\n",
    "    plt.plot(linMod.predict(X_test), label='predicted')\n",
    "    plt.show()\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(arrayOfDataToTrain)):\n",
    "    x =  arrayOfDataToTrain[i][arrayOfDataToTrain[i].columns[1:]]\n",
    "    y = arrayOfDataToTrain[i][arrayOfDataToTrain[i].columns[0]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=42)\n",
    "    print(pd.DataFrame([y_test.values,linearModel[i].predict(X_test)]))\n",
    "    #print('Actual:{} Precited:{}'.format(y_test.values,linearModel[i].predict(X_test)))\n",
    "    #print(y_test)\n",
    "    #print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So something went wrong, before we move on, we are going to check the correlation of the data we currently have.  Next step is to try and gather more data that can be used for weather predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arrayOfDataToTrain[0].columns)\n",
    "\n",
    "arrayOfDataToTrain[0].corr()[['AverageTemperature']].sort_values('AverageTemperature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = arrayOfDataToTrain[0].columns[1:].to_list()\n",
    "\n",
    "df2 = arrayOfDataToTrain[0][['AverageTemperature'] + predictors]\n",
    "print(arrayOfDataToTrain[0].Longitude)\n",
    "plt.rcParams['figure.figsize'] = [16, 22]\n",
    "\n",
    "# call subplots specifying the grid structure we desire and that \n",
    "# the y axes should be shared\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, sharey=True)\n",
    "\n",
    "# Since it would be nice to loop through the features in to build this plot\n",
    "# let us rearrange our data into a 2D array of 6 rows and 3 columns\n",
    "arr = np.array(predictors).reshape(3, 2)\n",
    "\n",
    "# use enumerate to loop over the arr 2D array of rows and columns\n",
    "# and create scatter plots of each meantempm vs each feature\n",
    "for row, col_arr in enumerate(arr):\n",
    "    for col, feature in enumerate(col_arr):\n",
    "        axes[row, col].scatter(df2[feature], df2['AverageTemperature'])\n",
    "        if col == 0:\n",
    "            axes[row, col].set(xlabel=feature, ylabel='AverageTemperature')\n",
    "        else:\n",
    "            axes[row, col].set(xlabel=feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, predicting temperature with greenhouse gases may not have been the best idea.  So let us try to use the data we do have by predicting how climate change will change.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainControl.getMonthDict()\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "for keys in mainControl.getMonthDict().keys():\n",
    "    plt.figure(figsize=(10,10))\n",
    "    df = mainControl.getMonthDict()[keys]\n",
    "    df = df.reset_index()\n",
    "    df = df.groupby(by='dt').agg('mean')['AverageTemperature']\n",
    "    plt.title('Temperature Variation ')\n",
    "    sns.lineplot(x=df.index, y=df)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have the data, might as well try out a MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "MLPModel = []\n",
    "for df in arrayOfDataToTrain:\n",
    "    x =  df[df.columns[1:]]\n",
    "    y = df[df.columns[0]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=42)\n",
    "    linMod = MLPRegressor().fit(X_train, y_train)\n",
    "    MLPModel.append(linMod)\n",
    "    #plt.title(f'month: {i}')\n",
    "    #plt.plot(y_test, label='real')\n",
    "    print(y_test)\n",
    "    print(linMod.predict(X_test))\n",
    "    plt.plot(linMod.predict(X_test), label='predicted')\n",
    "    #plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we are getting strange negative numbers in the pervious data... I think there might be an issue using Longitude and Latitude in it's current state.  So let us try and fix this.  We are going to use K-Means to order our data and create zones for our longitude and latitude to be apart of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from geohash2 import encode\n",
    "#for df in arrayOfDataToTrain:\n",
    "#    for index, row in df.iterrows():\n",
    "#        print(encode(row['Latitude'],row['Longitude'], precision=2))\n",
    "\n",
    "#datafile = cbook.get_sample_data('E:\\OneDrive - University of Georgia\\Data Science\\project\\usa.jpg')\n",
    "#img = imread(\"E:/OneDrive - University of Georgia/Data Science/project/usa.jpg\")\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "id_n= 7\n",
    "for df in arrayOfDataToTrain:\n",
    "    X = df.loc[:, ['Longitude', 'Latitude']]\n",
    "    #for index, row in df:\n",
    "    #    x,y = m(row['Longitude'], row['Latitude'])\n",
    "    #    plt.plot(x, y, 'ok', markersize=5)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=id_n, random_state=0).fit(X)\n",
    "    ptsymb = np.array(['b.','r.','m.','g.','c.','k.','b*','r*','m*','r^']);\n",
    "    plt.figure(figsize=(12,12))\n",
    "    id_label=kmeans.labels_\n",
    "    plt.ylabel('Latitude', fontsize=12)\n",
    "    plt.xlabel('Longitude', fontsize=12)\n",
    "    for i in range(id_n):\n",
    "        cluster=np.where(id_label==i)[0]\n",
    "        plt.plot(X.Longitude[cluster].values,X.Latitude[cluster].values ,ptsymb[i])\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm so, what are the min and max locations in regard to longitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainControl.getMonthDict()[1].iloc[arrayOfDataToTrain[0]['Longitude'].idxmin()]\n",
    "#arrayOfDataToTrain[0]['Longitude'].max()\n",
    "#mainControl.getMonthDict()[1].iloc[arrayOfDataToTrain[0]['Longitude'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
